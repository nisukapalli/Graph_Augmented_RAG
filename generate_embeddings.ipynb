{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nikhilisukapalli/Downloads/Capstone/mag_papers_0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/nikhilisukapalli/Downloads/Capstone/mag_papers_0')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.read_gpickle(\"mag_graph_cleaned.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers (nodes): 2393685\n",
      "Number of citations (edges): 225071\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of papers (nodes): {G.number_of_nodes()}\")\n",
    "print(f\"Number of citations (edges): {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 2393685\n"
     ]
    }
   ],
   "source": [
    "page_ranks = nx.pagerank(G, alpha=0.85)\n",
    "print(f\"Number of pages: {len(page_ranks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pageranks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(page_ranks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "/Users/nikhilisukapalli/opt/anaconda3/envs/graphqa2/lib/python3.9/site-packages/torch/__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilisukapalli/opt/anaconda3/envs/graphqa2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n",
      "4.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.__file__)\n",
    "\n",
    "import transformers\n",
    "import sentence_transformers\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(sentence_transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embedding = model.encode(\"This is a test sentence\")\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Electron Spin Resonance Investigations of Oxygen-Centered Free Radicals in Biological Systems', 'year': 1988, 'authors': ['Ronald P. Mason', 'Kim M. Morehouse'], 'fos': ['Hydroxyl radical', 'Autoxidation', 'Oxygen', 'Hyperfine structure', 'Photochemistry', 'Nuclear magnetic resonance', 'Radical', 'Electron paramagnetic resonance', 'Superoxide', 'Xanthine oxidase', 'Chemistry'], 'abstract': 'Oxygen-centered free radicals have been detected directly with ESR in a variety of biological processes such as lipid autoxidation,1 the enzymatic formation of superoxide by xanthine oxidase,2 and hydroxyl radical formation by the Y-irradiation of ice.3 Since the common isotope of oxygen is spin-less, no nuclear hyperfine interaction is possible, and the g-value and any hydrogen hyperfine coupling provide the only criteria for distinguishing an oxygen-centered free radical from other free radicals. The greatest limitation on the direct detection of oxygen-centered free radicals, aside from their high reactivity, is their paramagnetic properties.'}\n"
     ]
    }
   ],
   "source": [
    "for node_id, data in G.nodes(data=True):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 2393685 papers\n"
     ]
    }
   ],
   "source": [
    "paper_ids = []\n",
    "paper_texts = []\n",
    "\n",
    "for node_id, data in G.nodes(data=True):\n",
    "    if data.get('title') and data.get('abstract'):\n",
    "        text = (data.get('title', '') + ' ' + data.get('abstract', '')).strip()\n",
    "        if text:\n",
    "            paper_ids.append(node_id)\n",
    "            paper_texts.append(text)\n",
    "\n",
    "print(f\"Parsed {len(paper_texts)} papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_mb = process.memory_info().rss / (1024 * 1024)\n",
    "    print(f\"Current RAM usage: {mem_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch size 64 on samples 0–10000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 157/157 [09:33<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 64 took 574.10 seconds\n",
      "\n",
      "Processing batch size 128 on samples 10000–20000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 79/79 [11:05<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 128 took 666.29 seconds\n",
      "\n",
      "Processing batch size 256 on samples 20000–30000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 40/40 [09:48<00:00, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 256 took 589.64 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "batch_sizes = [64, 128, 256]\n",
    "chunk_size = 10000\n",
    "timings = {}\n",
    "\n",
    "for i, size in enumerate(batch_sizes):\n",
    "    start = i * chunk_size\n",
    "    end = start + chunk_size\n",
    "    sample = paper_texts[start:end]\n",
    "    print(f\"Processing batch size {size} on samples {start}–{end}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    batch_embeddings = model.encode(sample, show_progress_bar=True, batch_size=size)\n",
    "    timings[size] = time.time() - start_time\n",
    "    embeddings.extend(batch_embeddings)\n",
    "    print(f\"Batch size {size} took {timings[size]:.2f} seconds\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch size 256 on samples 30000–500000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1836 [00:08<4:35:08,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 batches...\n",
      "Current RAM usage: 1896.48 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 101/1836 [18:54<5:23:30, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 batches...\n",
      "Current RAM usage: 1943.68 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 201/1836 [37:36<4:53:04, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 batches...\n",
      "Current RAM usage: 1987.87 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 301/1836 [55:55<4:45:19, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 batches...\n",
      "Current RAM usage: 1284.52 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 401/1836 [1:14:30<4:02:22, 10.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 batches...\n",
      "Current RAM usage: 1234.12 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 501/1836 [1:31:25<3:47:48, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 batches...\n",
      "Current RAM usage: 1276.98 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 601/1836 [1:48:43<3:46:16, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 batches...\n",
      "Current RAM usage: 1320.38 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 701/1836 [2:07:24<3:18:22, 10.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 batches...\n",
      "Current RAM usage: 1364.24 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 801/1836 [2:27:56<3:44:39, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 batches...\n",
      "Current RAM usage: 1037.50 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 901/1836 [2:49:42<3:28:33, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 batches...\n",
      "Current RAM usage: 342.42 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1001/1836 [3:10:41<2:53:59, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 batches...\n",
      "Current RAM usage: 382.48 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1101/1836 [3:31:42<2:15:07, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 batches...\n",
      "Current RAM usage: 449.08 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1201/1836 [3:49:57<1:58:47, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 batches...\n",
      "Current RAM usage: 516.24 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1301/1836 [4:08:54<1:28:12,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 batches...\n",
      "Current RAM usage: 582.62 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 1401/1836 [4:31:00<1:51:31, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1400 batches...\n",
      "Current RAM usage: 495.63 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1501/1836 [4:52:05<1:13:12, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1500 batches...\n",
      "Current RAM usage: 503.15 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1601/1836 [5:13:07<1:23:38, 21.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1600 batches...\n",
      "Current RAM usage: 564.59 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1701/1836 [5:35:51<21:40,  9.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1700 batches...\n",
      "Current RAM usage: 349.45 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1801/1836 [5:52:30<05:52, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1800 batches...\n",
      "Current RAM usage: 422.50 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1836/1836 [5:58:20<00:00, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 256 took 21500.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings2 = []\n",
    "start = 30000\n",
    "end = 500000\n",
    "samples = paper_texts[start:end]\n",
    "print(f\"Processing batch size 256 on samples {start}–{end}...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(0, len(samples), 256)):\n",
    "    batch_embeddings2 = model.encode(samples[i:i + 256])\n",
    "    embeddings2.extend(batch_embeddings2)\n",
    "\n",
    "    if (i // 256) % 100 == 0:\n",
    "        print(f\"Completed {(i // 256)} batches...\")\n",
    "        print_memory_usage()\n",
    "        print()\n",
    "\n",
    "duration2 = time.time() - start_time\n",
    "print(f\"Batch size 256 took {duration2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch size 256 on samples 500000–1000000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1954 [00:09<5:07:17,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 batches...\n",
      "Current RAM usage: 925.82 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 101/1954 [22:54<6:42:35, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 batches...\n",
      "Current RAM usage: 421.03 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 201/1954 [43:05<5:22:00, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 batches...\n",
      "Current RAM usage: 497.32 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 301/1954 [1:10:34<7:50:46, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 batches...\n",
      "Current RAM usage: 384.47 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 401/1954 [1:35:25<6:28:02, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 batches...\n",
      "Current RAM usage: 438.60 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 501/1954 [1:58:07<6:07:18, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 batches...\n",
      "Current RAM usage: 506.52 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 601/1954 [2:21:44<4:54:44, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 batches...\n",
      "Current RAM usage: 515.70 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 701/1954 [2:42:30<4:17:41, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 batches...\n",
      "Current RAM usage: 581.36 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 801/1954 [3:02:47<3:55:18, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 batches...\n",
      "Current RAM usage: 647.79 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 901/1954 [5:01:24<4:46:56, 16.35s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 batches...\n",
      "Current RAM usage: 489.66 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1001/1954 [5:26:38<3:34:53, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 batches...\n",
      "Current RAM usage: 340.71 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1101/1954 [5:47:49<3:10:15, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 batches...\n",
      "Current RAM usage: 413.37 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 1201/1954 [6:13:28<3:28:09, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 batches...\n",
      "Current RAM usage: 405.63 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1301/1954 [6:34:06<2:08:09, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 batches...\n",
      "Current RAM usage: 474.25 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1401/1954 [6:53:27<1:44:47, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1400 batches...\n",
      "Current RAM usage: 540.25 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1501/1954 [7:14:25<1:27:07, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1500 batches...\n",
      "Current RAM usage: 574.64 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1601/1954 [7:34:45<1:10:24, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1600 batches...\n",
      "Current RAM usage: 523.18 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1701/1954 [7:55:38<55:36, 13.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1700 batches...\n",
      "Current RAM usage: 608.16 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1801/1954 [8:16:19<31:30, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1800 batches...\n",
      "Current RAM usage: 687.35 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1901/1954 [8:37:19<12:31, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1900 batches...\n",
      "Current RAM usage: 728.07 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1954/1954 [8:48:52<00:00, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 256 took 31732.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings3 = []\n",
    "start = 500000\n",
    "end = 1000000\n",
    "samples = paper_texts[start:end]\n",
    "print(f\"Processing batch size 256 on samples {start}–{end}...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(0, len(samples), 256)):\n",
    "    batch_embeddings3 = model.encode(samples[i:i + 256])\n",
    "    embeddings3.extend(batch_embeddings3)\n",
    "\n",
    "    if (i // 256) % 100 == 0:\n",
    "        print(f\"Completed {(i // 256)} batches...\")\n",
    "        print_memory_usage()\n",
    "        print()\n",
    "\n",
    "duration3 = time.time() - start_time\n",
    "print(f\"Batch size 256 took {duration3:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 470000 500000\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings), len(embeddings2), len(embeddings3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    'embeddings_1M.npz',\n",
    "    embeddings=np.array(embeddings, dtype=object),\n",
    "    embeddings2=np.array(embeddings2, dtype=object),\n",
    "    embeddings3=np.array(embeddings3, dtype=object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch size 256 on samples 1000000–1500000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1954 [00:13<7:31:58, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 batches...\n",
      "Current RAM usage: 1189.71 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 101/1954 [20:59<6:25:08, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 batches...\n",
      "Current RAM usage: 2392.49 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 201/1954 [41:54<5:58:15, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 batches...\n",
      "Current RAM usage: 431.52 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 301/1954 [1:02:54<5:39:50, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 batches...\n",
      "Current RAM usage: 576.51 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 401/1954 [11:31:11<6:10:14, 14.30s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 batches...\n",
      "Current RAM usage: 317.47 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 501/1954 [11:52:41<4:43:36, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 batches...\n",
      "Current RAM usage: 363.61 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 601/1954 [12:12:53<4:33:56, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 batches...\n",
      "Current RAM usage: 426.09 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 701/1954 [12:35:19<4:17:36, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 batches...\n",
      "Current RAM usage: 402.97 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 801/1954 [12:55:52<3:36:28, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 batches...\n",
      "Current RAM usage: 393.62 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 901/1954 [13:15:57<2:54:36,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 batches...\n",
      "Current RAM usage: 446.82 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1001/1954 [13:31:35<2:28:34,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 batches...\n",
      "Current RAM usage: 518.43 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1101/1954 [13:46:50<2:11:25,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 batches...\n",
      "Current RAM usage: 591.14 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 1201/1954 [14:02:21<1:57:56,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 batches...\n",
      "Current RAM usage: 663.43 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1301/1954 [18:57:02<3:45:50, 20.75s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 batches...\n",
      "Current RAM usage: 522.20 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1401/1954 [19:12:37<1:21:59,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1400 batches...\n",
      "Current RAM usage: 346.21 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1501/1954 [19:27:49<1:09:04,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1500 batches...\n",
      "Current RAM usage: 424.40 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1601/1954 [19:43:08<55:01,  9.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1600 batches...\n",
      "Current RAM usage: 503.02 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1701/1954 [20:34:53<46:50, 11.11s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1700 batches...\n",
      "Current RAM usage: 430.87 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1801/1954 [20:51:10<26:48, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1800 batches...\n",
      "Current RAM usage: 498.56 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1901/1954 [21:08:31<09:29, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1900 batches...\n",
      "Current RAM usage: 514.81 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1954/1954 [21:17:29<00:00, 39.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 256 took 76649.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings4 = []\n",
    "start = 1000000\n",
    "end = 1500000\n",
    "samples = paper_texts[start:end]\n",
    "print(f\"Processing batch size 256 on samples {start}–{end}...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(0, len(samples), 256)):\n",
    "    batch_embeddings4 = model.encode(samples[i:i + 256])\n",
    "    embeddings4.extend(batch_embeddings4)\n",
    "\n",
    "    if (i // 256) % 100 == 0:\n",
    "        print(f\"Completed {(i // 256)} batches...\")\n",
    "        print_memory_usage()\n",
    "        print()\n",
    "\n",
    "duration4 = time.time() - start_time\n",
    "print(f\"Batch size 256 took {duration4:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings4))\n",
    "\n",
    "np.savez_compressed(\n",
    "    'embeddings_1.5M.npz',\n",
    "    embeddings4=np.array(embeddings4, dtype=object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch size 256 on samples 1500000–2000000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1954 [00:23<12:59:29, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 batches...\n",
      "Current RAM usage: 4416.01 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 101/1954 [23:24<8:57:03, 17.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 batches...\n",
      "Current RAM usage: 264.92 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 201/1954 [42:36<5:57:41, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 batches...\n",
      "Current RAM usage: 371.10 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 301/1954 [1:04:14<5:02:57, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 batches...\n",
      "Current RAM usage: 435.88 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 401/1954 [1:27:16<7:14:51, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 batches...\n",
      "Current RAM usage: 365.91 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 501/1954 [1:48:38<5:07:17, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 batches...\n",
      "Current RAM usage: 441.34 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 601/1954 [2:09:23<4:47:28, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 batches...\n",
      "Current RAM usage: 517.61 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 701/1954 [2:30:01<7:33:48, 21.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 batches...\n",
      "Current RAM usage: 239.73 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 801/1954 [2:48:11<3:35:56, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 batches...\n",
      "Current RAM usage: 361.80 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 901/1954 [3:12:34<4:41:47, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 batches...\n",
      "Current RAM usage: 442.86 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1001/1954 [3:37:24<3:11:23, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 batches...\n",
      "Current RAM usage: 521.48 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1101/1954 [3:58:31<3:04:58, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 batches...\n",
      "Current RAM usage: 599.62 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 1201/1954 [4:23:31<3:25:34, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 batches...\n",
      "Current RAM usage: 676.71 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1301/1954 [4:45:05<2:12:23, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 batches...\n",
      "Current RAM usage: 754.95 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1401/1954 [5:05:27<1:54:41, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1400 batches...\n",
      "Current RAM usage: 831.46 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1501/1954 [5:27:57<1:43:03, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1500 batches...\n",
      "Current RAM usage: 861.86 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1601/1954 [5:47:51<1:06:02, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1600 batches...\n",
      "Current RAM usage: 940.15 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1701/1954 [6:06:28<46:56, 11.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1700 batches...\n",
      "Current RAM usage: 1011.88 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1801/1954 [6:24:41<27:51, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1800 batches...\n",
      "Current RAM usage: 1083.92 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1901/1954 [7:15:52<11:35, 13.12s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1900 batches...\n",
      "Current RAM usage: 704.33 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1954/1954 [7:26:33<00:00, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 256 took 26793.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings5 = []\n",
    "start = 1500000\n",
    "end = 2000000\n",
    "samples = paper_texts[start:end]\n",
    "print(f\"Processing batch size 256 on samples {start}–{end}...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(0, len(samples), 256)):\n",
    "    batch_embeddings5 = model.encode(samples[i:i + 256])\n",
    "    embeddings5.extend(batch_embeddings5)\n",
    "\n",
    "    if (i // 256) % 100 == 0:\n",
    "        print(f\"Completed {(i // 256)} batches...\")\n",
    "        print_memory_usage()\n",
    "        print()\n",
    "\n",
    "duration5 = time.time() - start_time\n",
    "print(f\"Batch size 256 took {duration5:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings5))\n",
    "\n",
    "np.savez_compressed(\n",
    "    'embeddings_2M.npz',\n",
    "    embeddings5=np.array(embeddings5, dtype=object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch size 256 on samples 2000000–2393685...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1538 [00:12<5:16:54, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 batches...\n",
      "Current RAM usage: 1385.68 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 101/1538 [19:23<4:32:25, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 batches...\n",
      "Current RAM usage: 1483.93 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 201/1538 [46:08<7:03:49, 19.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 batches...\n",
      "Current RAM usage: 285.93 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 301/1538 [1:11:03<3:57:01, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 batches...\n",
      "Current RAM usage: 312.04 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 401/1538 [1:30:45<3:44:34, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 batches...\n",
      "Current RAM usage: 401.62 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 501/1538 [1:52:07<3:56:04, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 batches...\n",
      "Current RAM usage: 487.92 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 601/1538 [2:13:39<3:34:55, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 batches...\n",
      "Current RAM usage: 574.04 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 701/1538 [2:33:47<2:47:43, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 batches...\n",
      "Current RAM usage: 661.98 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 801/1538 [2:52:35<2:13:37, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 batches...\n",
      "Current RAM usage: 743.28 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 901/1538 [3:11:12<2:14:24, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 batches...\n",
      "Current RAM usage: 823.90 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1001/1538 [3:33:25<1:34:46, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 batches...\n",
      "Current RAM usage: 603.93 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1101/1538 [3:50:56<1:18:40, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 batches...\n",
      "Current RAM usage: 684.76 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1201/1538 [4:10:04<1:10:12, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 batches...\n",
      "Current RAM usage: 762.74 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1301/1538 [4:30:34<46:54, 11.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 batches...\n",
      "Current RAM usage: 690.11 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1401/1538 [4:48:19<25:10, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1400 batches...\n",
      "Current RAM usage: 773.73 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1501/1538 [5:08:37<06:29, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1500 batches...\n",
      "Current RAM usage: 482.22 MB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1538/1538 [5:16:09<00:00, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size 256 took 18969.82 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings6 = []\n",
    "start = 2000000\n",
    "samples = paper_texts[start:]\n",
    "print(f\"Processing batch size 256 on samples {start}–{len(paper_texts)}...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(0, len(samples), 256)):\n",
    "    batch_embeddings6 = model.encode(samples[i:i + 256])\n",
    "    embeddings6.extend(batch_embeddings6)\n",
    "\n",
    "    if (i // 256) % 100 == 0:\n",
    "        print(f\"Completed {(i // 256)} batches...\")\n",
    "        print_memory_usage()\n",
    "        print()\n",
    "\n",
    "duration6 = time.time() - start_time\n",
    "print(f\"Batch size 256 took {duration6:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393685\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings6))\n",
    "\n",
    "np.savez_compressed(\n",
    "    'embeddings_2.4M.npz',\n",
    "    embeddings6=np.array(embeddings6, dtype=object)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphqa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
